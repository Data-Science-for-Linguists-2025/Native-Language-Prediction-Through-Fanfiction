{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as beau\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import pickle\n",
    "import nltk\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'natfinder/natfinder/manual-works'\n",
    "fics_df = pd.DataFrame(columns=['L1', 'author', 'title', 'tags', 'summary', 'notes', 'endnotes', 'work', 'rating', 'warnings', 'category', 'fandom', 'ships', 'charas', 'freeform'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(soup):\n",
    "    # basic info\n",
    "    try:\n",
    "        L1 = soup.find(class_='L1').text\n",
    "    except:\n",
    "        L1 = 'ERROR'\n",
    "    try:\n",
    "        author = soup.find(rel='author').text\n",
    "    except:\n",
    "        author = 'Anonymous'\n",
    "    try:\n",
    "        title = soup.find('h1').text\n",
    "    except:\n",
    "        title = 'NaN'\n",
    "    try:\n",
    "        tags = [t.text for t in soup.find_all(class_='tag')]\n",
    "    except:\n",
    "        tags = 'NaN'\n",
    "    try:\n",
    "        summary = soup.find('div', class_='summary module').text\n",
    "    except:\n",
    "        summary = 'NaN'\n",
    "    try:\n",
    "        notes = soup.find('div', class_='notes module').text\n",
    "    except:\n",
    "        notes = 'NaN'\n",
    "    try:\n",
    "        endnotes = soup.find('div', class_='end notes module').text\n",
    "    except:\n",
    "        endnotes = 'NaN'\n",
    "    try:\n",
    "        work = str([x.text for x in soup.find_all(id=\"chapters\")])\n",
    "    except:\n",
    "        work = 'NaN'\n",
    "    # tag info\n",
    "    try:\n",
    "        rating = [[a.text for a in t.find_all('a')] for t in soup.find_all(class_='rating tags')]\n",
    "    except:\n",
    "        rating = 'ERROR'\n",
    "    try:\n",
    "        warnings = [[a.text for a in t.find_all('a')] for t in soup.find_all(class_='warning tags')]\n",
    "    except:\n",
    "        warnings = 'ERROR'\n",
    "    try:\n",
    "        categories = [[a.text for a in t.find_all('a')] for t in soup.find_all(class_='category tags')]\n",
    "    except:\n",
    "        categories = 'ERROR'\n",
    "    try:\n",
    "        fandoms = [[a.text for a in t.find_all('a')] for t in soup.find_all(class_='fandom tags')]\n",
    "    except:\n",
    "        fandoms = 'ERROR'\n",
    "    try:\n",
    "        ships = [[a.text for a in t.find_all('a')] for t in soup.find_all(class_='relationship tags')]\n",
    "    except:\n",
    "        ships = 'NaN'\n",
    "    try:\n",
    "        charas = [[a.text for a in t.find_all('a')] for t in soup.find_all(class_='character tags')]\n",
    "    except:\n",
    "        charas = 'NaN'\n",
    "    try:\n",
    "        freeform = [[a.text for a in t.find_all('a')] for t in soup.find_all(class_='freeform tags')]\n",
    "    except:\n",
    "        freeform = 'NaN'\n",
    "    temp = pd.DataFrame({'L1':[L1], 'author':[author], 'title':[title],'tags':[tags], 'summary':[summary], 'notes':[notes], 'endnotes':[endnotes], 'work':[work], 'rating':[rating], 'warnings':[warnings], 'category':[categories], 'fandom':[fandoms], 'ships':[ships], 'charas':[charas], 'freeform':[freeform]})\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "i = 0\n",
    "for f in os.scandir(directory):\n",
    "    if f.name.endswith('.html'):\n",
    "        files.append(f.name)\n",
    "for f in files:\n",
    "    soup = beau(open(directory + '/' + f).read(), 'html.parser')\n",
    "    temp_df = extract_info(soup)\n",
    "    fics_df = pd.concat([fics_df, temp_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fics_df['work'] = fics_df.work.map(lambda x : re.sub(r'(?s).*Work Text:', '', re.sub(r'(?s)\\xa0\\n+.*', '', re.sub(r'\\s', ' ', x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fics_df_manual.pkl', 'wb') as file:\n",
    "    pickle.dump(fics_df, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
